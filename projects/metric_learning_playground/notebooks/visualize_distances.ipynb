{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b97e2bf-ff22-4c02-b2a8-8ef7c544fc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/dev/pepper/projects/metric_learning_playground\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99def0e0-d73b-4baa-baaa-0272d4de3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from numbers import Number\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6eb4ab-37ee-4ccc-bb9f-0960482cc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c62f30aa-a557-44ae-b78f-8fe63c33baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmcls.apis import multi_gpu_test, single_gpu_test\n",
    "from mmcls.datasets import build_dataset, build_dataloader\n",
    "from mmcls.models import build_classifier\n",
    "\n",
    "from src import *\n",
    "from src.apis import single_gpu_metric_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e86b7c-ce29-4262-958c-10485d186766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "model = 'lenet'\n",
    "dataset = 'mnist'\n",
    "ckpt_iter = 6000\n",
    "ckpt_path = osp.join('work_dirs', f'{model}_{dataset}', f'iter_{ckpt_iter}.pth')\n",
    "cfg_fp = osp.join('configs', model, f'{model}_{dataset}.py')\n",
    "assert osp.exists(cfg_fp)\n",
    "assert osp.exists(ckpt_path)\n",
    "\n",
    "# setup variables\n",
    "\n",
    "cfg = Config.fromfile(cfg_fp)\n",
    "# print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da752e7e-854c-45f9-b773-f3619d78be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(cfg.data.test, default_args=dict(test_mode=True))\n",
    "\n",
    "loader_cfg = dict(\n",
    "    samples_per_gpu=128,\n",
    "    workers_per_gpu=2,\n",
    "    num_gpus=1,\n",
    "    dist=False,\n",
    "    round_up=True,\n",
    ")\n",
    "test_loader_cfg = {\n",
    "    **loader_cfg,\n",
    "    \"shuffle\": False,\n",
    "    \"sampler_cfg\": None,\n",
    "    **cfg.data.get(\"test_dataloader\", {}),\n",
    "}\n",
    "data_loader = build_dataloader(dataset, **test_loader_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc188c0e-4121-4dc3-ae53-6f7333933f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: work_dirs/lenet_mnist/iter_6000.pth\n"
     ]
    }
   ],
   "source": [
    "model = build_classifier(cfg.model)\n",
    "checkpoint = load_checkpoint(model, ckpt_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01c5ddd2-b70c-4a07-a71b-c038eb9bfb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "CLASSES = checkpoint[\"meta\"][\"CLASSES\"]\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b2804a5-c434-4111-ac57-8aef9e4b2aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>                  ] 2999/10000, 2607.4 task/s, elapsed: 1s, ETA:     3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>  ] 9253/10000, 2899.1 task/s, elapsed: 3s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MMDataParallel(model, device_ids=[0])\n",
    "model.CLASSES = CLASSES\n",
    "\n",
    "preds, feats = single_gpu_metric_test(\n",
    "    model, data_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8691e130-87f7-43a3-baa5-6942b26d6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy_top-1 : 98.9\n",
      "\n",
      "accuracy_top-5 : 99.87\n",
      "\n",
      "f1_score : 98.91\n"
     ]
    }
   ],
   "source": [
    "eval_results = dataset.evaluate(\n",
    "    results=preds,\n",
    "    metric=[\"accuracy\", \"f1_score\"],\n",
    "    metric_options=None,\n",
    ")\n",
    "for k, v in eval_results.items():\n",
    "    if isinstance(v, np.ndarray):\n",
    "        v = [round(out, 2) for out in v.tolist()]\n",
    "    elif isinstance(v, Number):\n",
    "        v = round(v, 2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupport metric type: {type(v)}\")\n",
    "    print(f\"\\n{k} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505bf38a-02f4-4d33-acf2-25d700ae7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "labes = np.array(dataset.get_gt_labels())\n",
    "features = np.array(deepcopy(feats))\n",
    "\n",
    "colors = [\"C0\", \"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"C8\", \"C9\"]\n",
    "for label_idx in range(num_classes):\n",
    "    plt.scatter(\n",
    "        features[labels == label_idx, 0],\n",
    "        features[labels == label_idx, 1],\n",
    "        c=colors[label_idx],\n",
    "        s=1,\n",
    "    )\n",
    "plt.legend(\n",
    "    [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], loc=\"upper right\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
