{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33338754-d775-42ea-949a-45f18d79d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5960632c-6b79-4e53-934f-faf23ad78dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697bdd62-d39f-4eea-9f9b-46c884b68a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pair_ID\\tsentence_A\\tsentence_B\\trelatedness_score\\tentailment_judgment\\n1\\tA group of kids is playing in '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "\n",
    "text = res.text\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f61c8f-f2db-488e-b943-ec9d289950a7",
   "metadata": {},
   "source": [
    "We need this in a dataframe, which we build from the `text` string like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a439ac91-6b5b-426e-ad04-e51a2683a3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>entailment_judgment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                         sentence_A  \\\n",
       "0        1  A group of kids is playing in a yard and an ol...   \n",
       "1        2  A group of children is playing in the house an...   \n",
       "2        3  The young boys are playing outdoors and the ma...   \n",
       "3        5  The kids are playing outdoors near a man with ...   \n",
       "4        9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  relatedness_score  \\\n",
       "0  A group of boys in a yard is playing and a man...                4.5   \n",
       "1  A group of kids is playing in a yard and an ol...                3.2   \n",
       "2  The kids are playing outdoors near a man with ...                4.7   \n",
       "3  A group of kids is playing in a yard and an ol...                3.4   \n",
       "4  A group of kids is playing in a yard and an ol...                3.7   \n",
       "\n",
       "  entailment_judgment  \n",
       "0             NEUTRAL  \n",
       "1             NEUTRAL  \n",
       "2          ENTAILMENT  \n",
       "3             NEUTRAL  \n",
       "4             NEUTRAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(StringIO(text), sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4a411-8e16-46c5-bc9d-6736a97fc3fb",
   "metadata": {},
   "source": [
    "We will take all samples from `sentence_A` and build sentence embeddings for each - which we can then store in `faiss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9276bb87-1223-4d6b-8d2d-63229e97968e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A group of kids is playing in a yard and an old man is standing in the background',\n",
       " 'A group of children is playing in the house and there is no man standing in the background',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby',\n",
       " 'The kids are playing outdoors near a man with a smile',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data['sentence_A'].tolist()\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e2233-10a4-439a-b183-40c69693739a",
   "metadata": {},
   "source": [
    "And we will pull in the `sentence_B` column too, giving us ~4.5k unique sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9dc360-7134-46c7-b1dd-1b6c5bccdbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_b = data['sentence_B'].tolist()\n",
    "sentences.extend(sentence_b)\n",
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268b202-b174-486a-bf02-913e155f73d5",
   "metadata": {},
   "source": [
    "This isn't a particularly large number, so let's pull in a few more similar datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3093d58-bb9d-4bb6-a694-123697245cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762f56f5-2084-4a9d-9771-aef00933392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    # extract to dataframe\n",
    "    data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, on_bad_lines='skip')\n",
    "    # add to columns 1 and 2 to sentences list\n",
    "    sentences.extend(data[1].tolist())\n",
    "    sentences.extend(data[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a3227d-bd36-4dec-b64d-d37eb3320f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14505"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42894282-548d-4620-9c94-c8882f24f353",
   "metadata": {},
   "source": [
    "Before converting to our sentence embeddings, we will save to text file as backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3743dd-4858-482a-aefb-112c6d5a4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates and NaN\n",
    "sentences = [\n",
    "    sentence.replace('\\n', '') for sentence in list(set(sentences)) if type(sentence) is str\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3f285-88a2-41d1-87ea-7faa4ac18546",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    with open('sentences.txt', 'w') as fp:\n",
    "        fp.write('\\n'.join(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a620aa7-842e-4206-bfa2-5f8e8f7529fb",
   "metadata": {},
   "source": [
    "Now we have 14.5k unique sentences, a much better size. We'll go ahead and build the sentence embeddings (this can take some time...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f990fa4-d5c9-4974-b066-3f463aaa9948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d788aea212ca4678b06abe23d278efb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55946b44f92946bda94c7e9445e238a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162dcaca7c314fb88c03dc98f6f3b423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803b1fb74ff549c58fa756d2dfddf673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0335da1cabd24bbe9c9badcae4b39aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b68f85ca528455f91cb17554326a65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cce5f7b8544718a7cf75dd787f61c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b8774050c04a8893eb8c57ddf9fef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fa757892364dcb957ac1ad7e43434f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb937a340d148bba60495a1792d39c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5094aee5111447e18bf0df831f66fa2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eba8ad371c7465fa456b203eabc7bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c909f4d5ed542f08e10e9b05536459c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626b1e9-768f-4205-8e25-e0a286ddc3c9",
   "metadata": {},
   "source": [
    "We can save/load from file in the case fo needing to reload the notebook for any reason later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7c4bd0-6a8d-4291-85bd-6b82be009e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8287828-09a8-4189-ac51-279a062d0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    with open(f'./sim_sentences/embeddings_X.npy', 'wb') as fp:\n",
    "        np.save(fp, sentence_embeddings[0:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ae314e5-308a-4042-89d8-1d78ed28bf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_0.npy | 0 -> 256\n",
      "embeddings_1.npy | 256 -> 512\n",
      "embeddings_2.npy | 512 -> 768\n",
      "embeddings_3.npy | 768 -> 1024\n",
      "embeddings_4.npy | 1024 -> 1280\n",
      "embeddings_5.npy | 1280 -> 1536\n",
      "embeddings_6.npy | 1536 -> 1792\n",
      "embeddings_7.npy | 1792 -> 2048\n",
      "embeddings_8.npy | 2048 -> 2304\n",
      "embeddings_9.npy | 2304 -> 2560\n",
      "embeddings_10.npy | 2560 -> 2816\n",
      "embeddings_11.npy | 2816 -> 3072\n",
      "embeddings_12.npy | 3072 -> 3328\n",
      "embeddings_13.npy | 3328 -> 3584\n",
      "embeddings_14.npy | 3584 -> 3840\n",
      "embeddings_15.npy | 3840 -> 4096\n",
      "embeddings_16.npy | 4096 -> 4352\n",
      "embeddings_17.npy | 4352 -> 4608\n",
      "embeddings_18.npy | 4608 -> 4864\n",
      "embeddings_19.npy | 4864 -> 5120\n",
      "embeddings_20.npy | 5120 -> 5376\n",
      "embeddings_21.npy | 5376 -> 5632\n",
      "embeddings_22.npy | 5632 -> 5888\n",
      "embeddings_23.npy | 5888 -> 6144\n",
      "embeddings_24.npy | 6144 -> 6400\n",
      "embeddings_25.npy | 6400 -> 6656\n",
      "embeddings_26.npy | 6656 -> 6912\n",
      "embeddings_27.npy | 6912 -> 7168\n",
      "embeddings_28.npy | 7168 -> 7424\n",
      "embeddings_29.npy | 7424 -> 7680\n",
      "embeddings_30.npy | 7680 -> 7936\n",
      "embeddings_31.npy | 7936 -> 8192\n",
      "embeddings_32.npy | 8192 -> 8448\n",
      "embeddings_33.npy | 8448 -> 8704\n",
      "embeddings_34.npy | 8704 -> 8960\n",
      "embeddings_35.npy | 8960 -> 9216\n",
      "embeddings_36.npy | 9216 -> 9472\n",
      "embeddings_37.npy | 9472 -> 9728\n",
      "embeddings_38.npy | 9728 -> 9984\n",
      "embeddings_39.npy | 9984 -> 10240\n",
      "embeddings_40.npy | 10240 -> 10496\n",
      "embeddings_41.npy | 10496 -> 10752\n",
      "embeddings_42.npy | 10752 -> 11008\n",
      "embeddings_43.npy | 11008 -> 11264\n",
      "embeddings_44.npy | 11264 -> 11520\n",
      "embeddings_45.npy | 11520 -> 11776\n",
      "embeddings_46.npy | 11776 -> 12032\n",
      "embeddings_47.npy | 12032 -> 12288\n",
      "embeddings_48.npy | 12288 -> 12544\n",
      "embeddings_49.npy | 12544 -> 12800\n",
      "embeddings_50.npy | 12800 -> 13056\n",
      "embeddings_51.npy | 13056 -> 13312\n",
      "embeddings_52.npy | 13312 -> 13568\n",
      "embeddings_53.npy | 13568 -> 13824\n",
      "embeddings_54.npy | 13824 -> 14080\n",
      "embeddings_55.npy | 14080 -> 14336\n",
      "embeddings_56.npy | 14336 -> 14505\n"
     ]
    }
   ],
   "source": [
    "# saving data\n",
    "split = 256\n",
    "file_count = 0\n",
    "for i in range(0, sentence_embeddings.shape[0], split):\n",
    "    end = i + split\n",
    "    if end > sentence_embeddings.shape[0] + 1:\n",
    "        end = sentence_embeddings.shape[0] + 1\n",
    "    file_count = '0' + str(file_count) if file_count < 0 else str(file_count)\n",
    "    if SAVE:\n",
    "        with open(f'./sim_sentences/embeddings_{file_count}.npy', 'wb') as fp:\n",
    "            np.save(fp, sentence_embeddings[i:end, :])\n",
    "    print(f\"embeddings_{file_count}.npy | {i} -> {end}\")\n",
    "    file_count = int(file_count) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0266548b-c9c1-4dfb-8bc3-e32a52a90de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = sentence_embeddings.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e99410-7ba8-446b-9f8b-f7d459a3d842",
   "metadata": {},
   "source": [
    "# Flat L2 Index\n",
    "\n",
    "We initialize the flat L2 distance index `IndexFlatL2`, all we need is to specify the vector dimensionality - which in this case is `d==768` (to align with the sentence-BERT model output embeddings of size `768`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8352c568-1901-4141-98ac-346d2424754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211adf06-3f22-4754-a69b-f95c157acd62",
   "metadata": {},
   "source": [
    "Often, we will use indexes that require us to `train` them on our data before being used (if we are grouping or transforming the data in any way). `IndexFlatL2` however, is a simple operation and only requires that we calculate distances between vectors when we introduce our query vector `xq` during search. So, in this case, no training is required - which we can confirm by checking the `is_trained` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "510af275-bb2e-41a7-b871-5599075b7296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c5431-b199-4c74-bc59-53720d8254ea",
   "metadata": {},
   "source": [
    "Okay so once we're happy that our index is prepared, we then add new vectors using the `add` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd57be20-8220-4a24-84aa-a827b2dd7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80d11051-f9b0-4727-8588-6e9e173084c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac53a0-dc83-437b-baa8-ef3be3715ba5",
   "metadata": {},
   "source": [
    "Then search given a query `xq` and the number of nearest neighbors to return `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8adfc8-5b4c-4781-87c6-f910f19ea82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "xq = model.encode([\"Someone sprints with a football\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed4f38c1-dc1e-49ce-b1be-da28635ede42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5977  7573 12191   605]]\n",
      "CPU times: user 13.7 ms, sys: 58 µs, total: 13.8 ms\n",
      "Wall time: 12.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)  # k-nearest neigbors of the query vector | nprobe == 1: 6495 26392 61709 49932 | nprobe == 10: 36245  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71735217-5c8b-4283-b715-e862a3d45375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5977: A group of football players is running in the field',\n",
       " '7573: A group of people playing football is running in the field',\n",
       " '12191: Two groups of people are playing football',\n",
       " '605: A person playing football is running past an official carrying a football']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5654901-b684-4d72-a3db-badefcdbf46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A group of football players is running in the field'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[5977]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bf5a55-7015-40c4-955b-fa3383efed93",
   "metadata": {},
   "source": [
    "Clearly we have some good matches, everything returned includes people running with a football, or on the context of a football match. Now, if we'd rather extract the numerical vectors from faiss, we can do that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6c85009-5d14-4d98-b1db-349da10bbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.zeros((k, d))\n",
    "for i, val in enumerate(I[0].tolist()):\n",
    "    vecs[i, :] = index.reconstruct(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bef7d04d-eb36-44d8-a291-9d8d436dca34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01c0a6ab-5bec-4f70-99d4-c64aa98e493f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01627038,  0.22325905, -0.15037443, -0.30747256, -0.27122423,\n",
       "       -0.1059317 , -0.06460934,  0.04738167, -0.73349047, -0.37657675,\n",
       "       -0.76762825,  0.16902883,  0.53107637,  0.51176661,  1.14415872,\n",
       "       -0.08562914, -0.67240077, -0.96637076,  0.02545444, -0.21559833,\n",
       "       -1.25656569, -0.82982141, -0.09825029, -0.2185083 ,  0.50610232,\n",
       "        0.10527954,  0.50396878,  0.65242964, -1.39458752,  0.65847462,\n",
       "       -0.21525331, -0.22487442,  0.81818324,  0.08464327, -0.76141691,\n",
       "       -0.28928319, -0.09825825, -0.73046207,  0.07855757, -0.84354657,\n",
       "       -0.59242076,  0.77471346, -1.20920551, -0.2275794 , -1.30733597,\n",
       "       -0.23081481, -1.31322563,  0.01629069, -0.97285485,  0.19308175,\n",
       "        0.47424546,  1.18920863, -1.96741295, -0.70061159, -0.29638708,\n",
       "        0.60533714,  0.62407446, -0.70340377, -0.86754227,  0.1767319 ,\n",
       "       -0.19170497, -0.02951997,  0.22623591, -0.16695465, -0.80402559,\n",
       "       -0.45918933,  0.69675493, -0.24928212, -1.0147866 , -0.92174512,\n",
       "       -0.33842644, -0.39296755, -0.83734846, -0.11479232,  0.46049657,\n",
       "       -1.45211184,  0.60310435,  0.38696298, -0.04061237,  0.00453185,\n",
       "        0.24117799,  0.0539629 ,  0.07506462,  1.05115843,  0.12383968,\n",
       "       -0.71281099,  0.11722875,  0.52238196, -0.04581182,  0.26827076,\n",
       "        0.85985404, -0.35669914, -0.64667088, -0.54357958, -0.04310464,\n",
       "        0.95139128, -0.15605775, -0.4962534 , -0.11140191,  0.15610081])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7b4c7-73ac-48b9-8435-ea0f8f02b048",
   "metadata": {},
   "source": [
    "# Adding Partitioning to the Index\n",
    "\n",
    "faiss allows us to add an additional step to optimize our search effiency using variety of different methods.\n",
    "A popular approach is to partition the index into [Voronoi cells](https://en.wikipedia.org/wiki/Voronoi_diagram).\n",
    "Using this method we would take our query vector `xq`, identify the cell it belongs to, and then use our `IndexFlatL2` to search between the query vector `xq` and all indexed vectors belonging to that cell.\n",
    "We can also include vectors from other nearby cells too.\n",
    "\n",
    "We initialize our new partitioned index by first adding our previous `IndexFlatL2` operation as a quantization step (another step in the search process), and feeding this into the new `IndexIVFFlat` operation like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d99c4296-7a30-4324-95ca-368caae76d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 50\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caafab06-f00e-4f5d-924d-540e99a9661a",
   "metadata": {},
   "source": [
    "Here we've added a new parameter `nlist`. we use `nlist` to define how many partitions we'd like our index to have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05751460-3b32-4be6-9206-7b91860caf95",
   "metadata": {},
   "source": [
    "When we built the previous, `IndexFlatL2`-only index, we noted that no training was required as no grouping/tranformation was required to build that index.\n",
    "Now that we've added partitioning using `IndexIVFFlat`, this is no longer the case.\n",
    "Let's take a look at the `is_trained` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da465478-330d-4dda-801c-0e9e2453b2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97b633-ff1d-4077-8d3e-31af2a981408",
   "metadata": {},
   "source": [
    "So, what we need to do now is `train` our index on our data, which we do before adding any data to the index (otherwise the index cannot know how to group each vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24d02a87-9172-4754-b866-00fc1b806623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.train(sentence_embeddings)\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d9746-070d-4e83-be3b-58b14ecc6d91",
   "metadata": {},
   "source": [
    "Now our index is trained, we add our data just as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "568cb5d7-689d-4d6b-95ad-3ad63b215a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.add(sentence_embeddings)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4fbf8-74b9-44ee-bff3-4c3c48cbc932",
   "metadata": {},
   "source": [
    "Let's search again using the same indexed sentence embeddings and the same query `xq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4dd1db96-90f4-48dd-8449-967ddff71230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5977  7573 12191   605]]\n",
      "CPU times: user 1.34 ms, sys: 192 µs, total: 1.53 ms\n",
      "Wall time: 900 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a2b80-781c-485e-a3b5-00393966be2a",
   "metadata": {},
   "source": [
    "We can increase the number of nearby cells to serach too with `nprobe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45bca78b-92b5-4bfc-ad28-7bd5f79eede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.nprobe = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff5f0e44-3fac-477c-9b09-29bb85954a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5977  7573 12191   605]]\n",
      "CPU times: user 2.39 ms, sys: 1.96 ms, total: 4.36 ms\n",
      "Wall time: 3.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72cd26-8f26-4c0c-852f-b3a4a2d4eb04",
   "metadata": {},
   "source": [
    "Increasing the number of `nprobe` will improve the accuracy of our search, but cost time. Our earlier `IndexFlatL2`-only search was exhaustive (it compared every single vector) and so it identified the closest matches with a perfect accuracy.\n",
    "The smaller our `nprobe` value, the smaller scope that we search.\n",
    "We received perfect results (that matched our previous `IndexFlatL2`-only results - `7460`, `10940`, `3781`, `5747`), however, if we found that we were not getting closely matching results, we could simply bump `nprobe` up further - improving accuracy, but increasing time-taken too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99beba4-c5a1-4c31-b1b2-648776c80de4",
   "metadata": {},
   "source": [
    "For IVF (and IMI) indexes, before attempting to use the `reconstruct` method, we need to call the `make_direct_map` method - otherwise we will return a `RunetimeError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "106c310f-0d82-4f8e-8677-315e1c2778db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42223325,  0.25445822,  2.1197274 , -0.04604523,  0.15920906,\n",
       "       -0.03425917,  0.18358617, -1.2359186 ,  0.43517134, -0.41971323,\n",
       "       -1.1047288 ,  0.59653074,  0.70958394,  0.10358086, -1.2594174 ,\n",
       "       -0.29242876,  0.02118083, -1.034143  , -0.2594775 , -0.95105344,\n",
       "       -1.311581  , -0.46893784, -0.60118765,  0.02630937, -0.1638549 ,\n",
       "        0.894012  , -0.17102613,  0.43290544, -1.4750891 ,  0.69652313,\n",
       "        0.01709623,  0.07306284,  0.31114212, -0.458619  , -0.8999929 ,\n",
       "       -0.19464928,  0.4906521 , -0.53843707,  0.24446803,  0.59129316,\n",
       "       -0.5541887 ,  0.44797096, -0.0782951 , -0.13418755, -0.17247899,\n",
       "       -0.6924553 , -0.4919634 ,  0.72926825,  0.96075565, -1.1803845 ,\n",
       "       -0.10572469, -0.44152603, -0.8944549 , -0.21623953, -0.8901376 ,\n",
       "        0.10714849,  0.26428026, -1.5570687 , -0.6085926 , -0.21136774,\n",
       "       -1.4472393 ,  0.23004436,  0.7577629 ,  0.732899  , -1.0625232 ,\n",
       "        0.20482826,  0.35931626,  0.10953128,  0.30508724, -0.38363704,\n",
       "        0.30649713, -0.38917175, -0.03328936,  0.3597523 , -0.04812937,\n",
       "       -0.93124896, -0.21257997,  0.7547677 ,  1.040337  ,  0.6976928 ,\n",
       "        0.33157203,  0.20043017,  0.44023773, -0.8412738 ,  0.7621054 ,\n",
       "        0.10075461,  0.9588011 , -0.33457652, -0.22183943, -0.06901035,\n",
       "       -0.276292  , -0.11657605,  0.26204583, -0.25354347, -0.25560346,\n",
       "        0.16711985, -0.01539174,  0.05225836, -0.0531781 ,  0.3770063 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.make_direct_map()\n",
    "index.reconstruct(7460)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4529a9-de4b-4fa9-b21d-6bd75a7e8170",
   "metadata": {},
   "source": [
    "We've now significantly reduced the search time, what can we do next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5ba24-c392-4376-8e2c-8cb40f629ce2",
   "metadata": {},
   "source": [
    "# Quantization\n",
    "\n",
    "Well, when storing these vectors we're storing the full (e.g. `Flat`) vector. Now in very big datasets this can quickly become a problem. Typically, we look at big datasets, and when working with large dataset we will find thgat storing the full vectors consumes too much space.\n",
    "\n",
    "Fortunately, faiss comes with the ability to compress our bectors using transformations based on Product Quanitzation (PQ).\n",
    "But, what is PQ?\n",
    "Well, we can view it as an additional approximation step similar to our use of IVF, which allowed us to approximate by reducing the scope of our search.\n",
    "PQ is slightly different however, and approximates the distance (or similarity) calculation instead.\n",
    "\n",
    "Some tutorials [here](https://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/).\n",
    "\n",
    "PQ achieves this approximated distance operation by compressing the vectors themselves.\n",
    "This consist of a few steps:\n",
    "\n",
    "1. We split every original vector into several subvectors\n",
    "2. For each set of subvector, we perform a clustering operation, creating many centroids for each subvector set\n",
    "3. In our vector of subvectors, we replace each subvector with the ID of it's nearest centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0517a27-a527-49ec-9625-6bfa838f4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8  # number of centroid IDs in final compressed vectors\n",
    "bits = 8 # number of bits in each centroid\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)  # we keep the same L2 distance flat index\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c5f777f-a564-4a01-9b4c-f73016679896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61f987a4-ce58-4aa1-9c79-4097f7ecafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c74494c4-e341-4cc3-9dd7-0d7a2a5fdb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93506cf-c40f-4665-bb61-95c914d5bb5b",
   "metadata": {},
   "source": [
    "Let's compare it to our previous index without PQ, and an `nprobe` value of `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0740fc01-14ad-4f1d-9d3c-d904c046d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.nprobe = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd3126df-6d77-4f45-90cc-138cfbcbc0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1059  605 6440  768]]\n",
      "CPU times: user 960 µs, sys: 0 ns, total: 960 µs\n",
      "Wall time: 698 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88507da6-c634-4476-af25-6fd2efdf2750",
   "metadata": {},
   "source": [
    "Though adding PQ reduced the search time significantly, a small difference on a dataset of this size, but when scaled ot larger dataset this can make a huge difference.\n",
    "\n",
    "Now, we should also notice the slightly different reqults being returned.\n",
    "Beforehand, with our exhaustive L2 search we were returning different results that were very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "650e63a1-e6c6-4531-a644-8a91acbb1746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1059: A football player is running past an official carrying a football',\n",
       " '605: A person playing football is running past an official carrying a football',\n",
       " '6440: Different teams are playing football on a field',\n",
       " '768: position in football played by a team member']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6f5f3-d9f8-4d3e-9e92-41c955fb654f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
